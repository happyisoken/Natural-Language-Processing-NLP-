{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1b2b71-0a24-4960-9e3b-324ba6568085",
   "metadata": {},
   "source": [
    "#### Introduction to Natural Language Processing(NLP)\n",
    "\n",
    "##### Syntax and Semantics of English Language\n",
    "\n",
    "###### Syntax: \n",
    "Refers to the grammatical structure of a sentence. For instance Noun phrase, verb phrase, determiner, adjective, noun, verb and adverb. \n",
    "\n",
    "The goal for understanding the syntax of language is to be able to understand the meaning of the language.\n",
    "\n",
    "###### Semantics:\n",
    "Refers to the actual meaning of the sentence.\n",
    "\n",
    "###### Building your own tagger?\n",
    "- Corpora: \n",
    "    - universal dependencies corpus (free)\n",
    "    - Penn Treebank corpus(not free)\n",
    "\n",
    "###### Parsing Resources\n",
    "1. SpaCy\n",
    "    - python, high accuracy, fast (https://spacy.io/)\n",
    "2. Stanford Core NLP\n",
    "    - java, high accuracy, medium (https://nlp.stanford.edu/software/corenlp.shtml)\n",
    "3. NLTK\n",
    "    - python, low accuracy, fast (https://www.nltk.org)\n",
    "\n",
    "##### Part of speech tags(POS Tags)\n",
    "Part of speech tags - syntax of a sentence. We can infer a part of speech tags based on the context of the sentence.\n",
    "\n",
    "###### What to do with POS tags\n",
    "1. Keyword Extraction: Nouns and Noun phrases are often the most significant pieces of information.\n",
    "2. Entity Extraction: These are names of people, places etc\n",
    "\n",
    "##### Process of Keyword Extraction: \n",
    "Extract candidate keywords, and rerank their relevance to the document based on a chosen (custom) metric.\n",
    "\n",
    "###### Where is Keyword Extraction used?\n",
    "1. Customer feedback analysis\n",
    "\n",
    "#### Language Models(LM)\n",
    "Language Models provides a list of probable explanations/representations of a given sentence.\n",
    "Using grammar and syntax provides just one representation of the text. But there can be more than one meaning of a sentence.\n",
    "\n",
    "###### Understanding Language Models\n",
    "A model that can predict the probability of a given word given a list of previous words:\n",
    "\n",
    "P(NLP) = p(N) * p(L|N) * p(P|NL)\n",
    "\n",
    "###### How do we compute these probabilites?\n",
    "- Bigrams model\n",
    "- Trigram\n",
    "- 4-gram\n",
    "- 5-gram\n",
    "- Etc\n",
    "\n",
    "##### Applications of Language Models\n",
    "1. Spelling Correction: For spelling correction, probability of incorrect sentence will be much smaller than correct sentence.\n",
    "2. Speech recognition: For instance, the words weather and whether.\n",
    "3. Machine translation: selecting appropriate sequence while translating from one language to another can also use probability of sequence for providing more appropriate translations.\n",
    "4. Predictive text: by looking at previous sequence of words, language model can predict next word, this feature was recently introduced in android phone keyboard by google.\n",
    "\n",
    "##### Word Embeddings\n",
    "Word embeddings are vector representation of a given word to capture the semantics of the word.\n",
    "\n",
    "A vector is a list of numbers that can capture the meaning of a word.\n",
    "\n",
    "##### Examples of word embeddings\n",
    "1. WOrd2Vec\n",
    "2. Glove\n",
    "These models represent the knowledge of the earth in over 300 dimensions.\n",
    "\n",
    "##### How does Word2Vec work?\n",
    "Word2Vec is a method to construct such an embedding. It can be obtained using two methods (both involving Neural Networks): Skip Gram and Common Bag of Words(CBOW)\n",
    "\n",
    "##### CBOW Model\n",
    "CBOW Model: This method takes the context of each word as the input and tries to predict the word corresponding to the context.\n",
    "\n",
    "CBOW is faster and has better representations for more frequent words.\n",
    "\n",
    "##### Skip Gram Model\n",
    "Skip Gram: We take a target word and try to predict its context.\n",
    "\n",
    "Skip Gram works well with small amount of data and is found to represent rare words well.\n",
    "\n",
    "##### Where can word embeddings be used?\n",
    "1. Used as a thesaurus\n",
    "2. Topic identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d1e16-1f50-4ea7-a648-a7b29fe0a0dc",
   "metadata": {},
   "source": [
    "#### Introduction to Natural Language Processing(NLP)\n",
    "\n",
    "Natural Language Processing is an automated way to understand and analyze human languages and extract information from such data by applying machine algorithms. The data content can be text argument, audio, image or video.\n",
    "\n",
    "Sometimes, it is also referred to as a field of computer science or AI to extract the linguistic information from the underlying data. It enables machines or computers to derive meaning from human or natural language input.\n",
    "\n",
    "#### Why NLP\n",
    "The world is now connected globally due to the advancement of technology of technology and devices. Including:\n",
    "- Analyzing tons of data generated in the form of texts, audios, image or videos.\n",
    "- Identifying various languages and dialects.\n",
    "- Applying quantitative analysis on huge collections of data\n",
    "- Handling ambiguities while interpreting data and extracting information.\n",
    "\n",
    "With the advancement of technology and services, the world is now a global village.\n",
    "\n",
    "One of the main goal of NLP is to understand various languages, process them and extract information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda9e26-a9a2-4e4c-af29-a48361b25073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc8661-e11c-4a7c-97a1-7fb72cf1a146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e618e2-ce0f-4cb9-adfc-4c20b010466a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c6064-990b-47c4-983e-a11e2d8eaa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b40bb5-fc47-49c0-835b-34cbb6c05ddc",
   "metadata": {},
   "source": [
    "#### Sentence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a782aff-b0a6-41b2-9b78-5a725fa0f45c",
   "metadata": {},
   "source": [
    "##### Eliminate punctuation and stopwords from the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539d4259-edc1-46a3-9ecc-6cb6eda99d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e8b3f-8a5b-4662-9e17-15a1f80ddd76",
   "metadata": {},
   "source": [
    "In the word of text analysis, stopwords usually have little of a meaning. E.g. I, me, myself, you, yours etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34453a4d-ae94-4d7c-a4ab-683d9a55819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View first 10 stopwords present in the english corpus\n",
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0d80e9-2247-4441-8027-c1b6a5a03037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a test sentence to analyze\n",
    "test_sentence = 'This is my first test string. Wow!! we are doing just fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bcf1e7b-9894-4801-9e49-a74c38ba5ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'y',\n",
       " ' ',\n",
       " 'f',\n",
       " 'i',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 's',\n",
       " 't',\n",
       " 'r',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'W',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'j',\n",
       " 'u',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eliminate the puntuation in form of characters and print them\n",
    "no_punctuation = [char for char in test_sentence if char not in string.punctuation]\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762b296d-0609-41f1-97c6-953d89e7bb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my first test string Wow we are doing just fine'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now eliminate the punctuation and print them as a whole sentence\n",
    "no_punctuation = ''.join(no_punctuation)\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326718af-22be-49f0-a222-513ebfce6d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'my',\n",
       " 'first',\n",
       " 'test',\n",
       " 'string',\n",
       " 'Wow',\n",
       " 'we',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'just',\n",
       " 'fine']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split each words present in the new sentence\n",
    "no_punctuation.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5bad9c-6165-41f3-9043-75247ff6888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now eliminate stopwords\n",
    "clean_sentence = [word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf39f1b-0176-46d5-92f6-54937b691817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'test', 'string', 'Wow', 'fine']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the final cleaned sentence\n",
    "clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118e82c-999d-4e1f-b9cd-f3392159964d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
